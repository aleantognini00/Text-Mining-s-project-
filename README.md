# Text Mining's project

This Text Mining project aims to explore and compare natural language processing techniques on real-world textual data.
After a preprocessing phase (tokenization, stopword removal, lemmatization), classical models such as Bag of Words and TF-IDF are applied to represent the text.
An unsupervised analysis follows using LDA (Latent Dirichlet Allocation) to identify latent topics within the documents.
In the second part of the project, transformer-based models—specifically BERT—are introduced to generate richer and more accurate contextual embeddings.
These representations are then used in supervised classification tasks, highlighting the advantages of neural approaches over traditional ones.
Interactive visualizations (using pyLDAvis, matplotlib, and seaborn) support the interpretation of the results.
The project is fully developed in Python, leveraging libraries such as scikit-learn, transformers, nltk, gensim, and pandas.
The entire workflow provides a complete and modular example of an NLP pipeline, from text preparation to advanced modeling.
